{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment for Module 6\n",
    "\n",
    "In this assignment you will continue working with the housing price per district from the previous module assignment, this time training SVM models, both for regression and classification.\n",
    "\n",
    "#### Getting the data for the assignment (similar to the notebook from chapter 2 of Hands-On...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the categories in the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'<1H OCEAN':'LESS_1H_OCEAN', 'INLAND':'INLAND', 'ISLAND':'ISLAND', 'NEAR BAY':'NEAR_BAY', 'NEAR OCEAN':'NEAR_OCEAN'}\n",
    "housing['ocean_proximity'] = housing['ocean_proximity'].map(lambda s: d[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 2 more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median()\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables based on the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
    "housing = housing.drop('ocean_proximity', axis=1)\n",
    "housing = housing.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 16 columns):\n",
      "longitude                   20640 non-null float64\n",
      "latitude                    20640 non-null float64\n",
      "housing_median_age          20640 non-null float64\n",
      "total_rooms                 20640 non-null float64\n",
      "total_bedrooms              20640 non-null float64\n",
      "population                  20640 non-null float64\n",
      "households                  20640 non-null float64\n",
      "median_income               20640 non-null float64\n",
      "median_house_value          20640 non-null float64\n",
      "rooms_per_household         20640 non-null float64\n",
      "population_per_household    20640 non-null float64\n",
      "INLAND                      20640 non-null uint8\n",
      "ISLAND                      20640 non-null uint8\n",
      "LESS_1H_OCEAN               20640 non-null uint8\n",
      "NEAR_BAY                    20640 non-null uint8\n",
      "NEAR_OCEAN                  20640 non-null uint8\n",
      "dtypes: float64(11), uint8(5)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition into train and test\n",
    "\n",
    "Use train_test_split from sklearn.model_selection to partition the dataset into 70% for training and 30% for testing.\n",
    "\n",
    "You can use the 70% for training set as both training and validation by using cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'median_house_value'\n",
    "features = list(train_set.columns)\n",
    "features = [f for f in features if f!=target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = train_set[features]\n",
    "y_tr = train_set[[target]]\n",
    "\n",
    "X_te = test_set[features]\n",
    "y_te = test_set[[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, use StandardScaler from sklearn.preprocessing to normalize the training and testing data, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ehsanul\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Ehsanul\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n",
      "C:\\Users\\Ehsanul\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_te = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression on original features (no transformations) --- benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [70142.55721218 67456.39127204 67318.3258893  70866.26065275]\n",
      "Mean: 68945.88375656874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_scores = cross_val_score(LinearRegression(), train_set[features], train_set[target], scoring=\"neg_mean_squared_error\", cv=4)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Support Vector Machines for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) In this exercise your goal is to tune SVR with FBR kernel, and make the average score mean_squared_error over 3-folds (cv=3) below 58000. \n",
    "\n",
    "You are encouraged to try optimizing any of the hyper-parameters of SVR\n",
    "\n",
    "See http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html for more details\n",
    "\n",
    "However, as a hint, you can focus on C and gamma. \n",
    "\n",
    "Hint 2: if when you try different values for a hyper-parameter, the optimal models corresponds to one of the extreme values in your range, that probably means you can keep improving your solution by considering values beyond the current range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'C': [100, 1000, 10000, 100000], 'gamma': [0.01, 0.1, 0.5, 1, 5]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "C_vals = [100,1000,10000,100000] ## YOUR VALUES FOR C ##\n",
    "gamma_vals = [.01,.1,.5,1,5] ## YOUR VALUES FOR gamma ## \n",
    "\n",
    "param_grid = [{'C':C_vals, 'gamma':gamma_vals}]\n",
    "grid_search_rbf = GridSearchCV(SVR(kernel='rbf'), param_grid, cv=3,scoring='neg_mean_squared_error')\n",
    "grid_search_rbf.fit(X_tr, np.ravel(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100000, 'gamma': 0.1}\n",
      "57255.36016378938\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_rbf.best_params_)\n",
    "print(np.sqrt(-grid_search_rbf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running Grid search, the best hyper parameters obtained are C = 100000 and gamma = .1\n",
    "\n",
    "With this parameters, RMSE is 57255.36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56466.15041953526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "final_model = grid_search_rbf.best_estimator_   ## THIS SHOULD BE THE BEST GRID_SEARCH ##\n",
    "\n",
    "y_te_estimation = final_model.predict(X_te)\n",
    "\n",
    "final_mse = mean_squared_error(y_te, y_te_estimation)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(final_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has RMSE value 56466.15 with test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. SVM for Classification\n",
    "\n",
    "Now we transform the continuous target into a binary variable, indicating whether or not the price is above the average $179700\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179700.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(housing[['median_house_value']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_b = 1*np.ravel(y_tr>=179700.0)\n",
    "y_te_b = 1*np.ravel(y_te>=179700.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ehsanul\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = LinearSVC(random_state=42)\n",
    "lin_clf.fit(X_tr, y_tr_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8384551495016611"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lin_clf.predict(X_tr)\n",
    "accuracy_score(y_tr_b, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy with training set is .8384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8394702842377261"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_te = lin_clf.predict(X_te)\n",
    "accuracy_score(y_te_b, y_pred_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy with test set is .8394"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Does SVC (with default hyper-parameters) improve the performance of the linear SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "\n",
    "clf = SVC(kernel='rbf',gamma='auto')\n",
    "clf.fit(X_tr, y_tr_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866140642303433"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_tr)\n",
    "accuracy_score(y_tr_b, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With training set, SVC with default hyper parameters has accuracy .8661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8624031007751938"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = clf.predict(X_te)\n",
    "accuracy_score(y_te_b, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC with default hyper parameters is an improvement over the Linear SVM.\n",
    "\n",
    "SVC with default hyper parameters = accuracy .8624 on test set\n",
    "Linear SVM = accuracy .8394 on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Use randomized search to tune hyper-parameters of SVC and improve its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ehsanul\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] C=239.61300573046918, gamma=0.0056810074794576195 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=239.61300573046918, gamma=0.0056810074794576195, total=   4.7s\n",
      "[CV] C=239.61300573046918, gamma=0.0056810074794576195 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=239.61300573046918, gamma=0.0056810074794576195, total=   4.5s\n",
      "[CV] C=239.61300573046918, gamma=0.0056810074794576195 ...............\n",
      "[CV]  C=239.61300573046918, gamma=0.0056810074794576195, total=   4.0s\n",
      "[CV] C=1086.479308854202, gamma=0.002450473147799242 .................\n",
      "[CV] .. C=1086.479308854202, gamma=0.002450473147799242, total=   5.3s\n",
      "[CV] C=1086.479308854202, gamma=0.002450473147799242 .................\n",
      "[CV] .. C=1086.479308854202, gamma=0.002450473147799242, total=   5.6s\n",
      "[CV] C=1086.479308854202, gamma=0.002450473147799242 .................\n",
      "[CV] .. C=1086.479308854202, gamma=0.002450473147799242, total=   5.1s\n",
      "[CV] C=1018.8304697721801, gamma=0.028014887342307688 ................\n",
      "[CV] . C=1018.8304697721801, gamma=0.028014887342307688, total=  11.7s\n",
      "[CV] C=1018.8304697721801, gamma=0.028014887342307688 ................\n",
      "[CV] . C=1018.8304697721801, gamma=0.028014887342307688, total=  11.3s\n",
      "[CV] C=1018.8304697721801, gamma=0.028014887342307688 ................\n",
      "[CV] . C=1018.8304697721801, gamma=0.028014887342307688, total=  11.3s\n",
      "[CV] C=1083.9681407847665, gamma=0.0031019047053441693 ...............\n",
      "[CV]  C=1083.9681407847665, gamma=0.0031019047053441693, total=   5.6s\n",
      "[CV] C=1083.9681407847665, gamma=0.0031019047053441693 ...............\n",
      "[CV]  C=1083.9681407847665, gamma=0.0031019047053441693, total=   6.2s\n",
      "[CV] C=1083.9681407847665, gamma=0.0031019047053441693 ...............\n",
      "[CV]  C=1083.9681407847665, gamma=0.0031019047053441693, total=   5.5s\n",
      "[CV] C=778.9532014603574, gamma=0.001148453568316582 .................\n",
      "[CV] .. C=778.9532014603574, gamma=0.001148453568316582, total=   4.2s\n",
      "[CV] C=778.9532014603574, gamma=0.001148453568316582 .................\n",
      "[CV] .. C=778.9532014603574, gamma=0.001148453568316582, total=   4.7s\n",
      "[CV] C=778.9532014603574, gamma=0.001148453568316582 .................\n",
      "[CV] .. C=778.9532014603574, gamma=0.001148453568316582, total=   4.6s\n",
      "[CV] C=883.6515861976594, gamma=0.003126862409043782 .................\n",
      "[CV] .. C=883.6515861976594, gamma=0.003126862409043782, total=   5.1s\n",
      "[CV] C=883.6515861976594, gamma=0.003126862409043782 .................\n",
      "[CV] .. C=883.6515861976594, gamma=0.003126862409043782, total=   5.3s\n",
      "[CV] C=883.6515861976594, gamma=0.003126862409043782 .................\n",
      "[CV] .. C=883.6515861976594, gamma=0.003126862409043782, total=   5.1s\n",
      "[CV] C=814.7046442629387, gamma=0.002332560691107216 .................\n",
      "[CV] .. C=814.7046442629387, gamma=0.002332560691107216, total=   5.7s\n",
      "[CV] C=814.7046442629387, gamma=0.002332560691107216 .................\n",
      "[CV] .. C=814.7046442629387, gamma=0.002332560691107216, total=   5.5s\n",
      "[CV] C=814.7046442629387, gamma=0.002332560691107216 .................\n",
      "[CV] .. C=814.7046442629387, gamma=0.002332560691107216, total=   5.6s\n",
      "[CV] C=743.6139993285233, gamma=0.04260655630161863 ..................\n",
      "[CV] ... C=743.6139993285233, gamma=0.04260655630161863, total=  10.9s\n",
      "[CV] C=743.6139993285233, gamma=0.04260655630161863 ..................\n",
      "[CV] ... C=743.6139993285233, gamma=0.04260655630161863, total=  10.9s\n",
      "[CV] C=743.6139993285233, gamma=0.04260655630161863 ..................\n",
      "[CV] ... C=743.6139993285233, gamma=0.04260655630161863, total=  11.4s\n",
      "[CV] C=354.17762765676434, gamma=0.010121864696525887 ................\n",
      "[CV] . C=354.17762765676434, gamma=0.010121864696525887, total=   6.0s\n",
      "[CV] C=354.17762765676434, gamma=0.010121864696525887 ................\n",
      "[CV] . C=354.17762765676434, gamma=0.010121864696525887, total=   7.2s\n",
      "[CV] C=354.17762765676434, gamma=0.010121864696525887 ................\n",
      "[CV] . C=354.17762765676434, gamma=0.010121864696525887, total=   5.4s\n",
      "[CV] C=848.1441358462207, gamma=0.002015649976077318 .................\n",
      "[CV] .. C=848.1441358462207, gamma=0.002015649976077318, total=   5.6s\n",
      "[CV] C=848.1441358462207, gamma=0.002015649976077318 .................\n",
      "[CV] .. C=848.1441358462207, gamma=0.002015649976077318, total=   4.9s\n",
      "[CV] C=848.1441358462207, gamma=0.002015649976077318 .................\n",
      "[CV] .. C=848.1441358462207, gamma=0.002015649976077318, total=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=None,\n",
       "          param_distributions={'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000002CEFA285F8>, 'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000002CEFA28B00>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "\n",
    "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(100, 1000)}\n",
    "rnd_search_cv = RandomizedSearchCV(clf, param_distributions, n_iter=10, verbose=2)\n",
    "rnd_search_cv.fit(X_tr, y_tr_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1018.8304697721801, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.028014887342307688,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8971483942414175"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rnd_Classifier = rnd_search_cv.predict(X_tr)\n",
    "accuracy_score(y_tr_b, y_pred_rnd_Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is .8971 on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8770994832041343"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final = rnd_search_cv.best_estimator_   ## THIS IS THE BEST GRID_SEARCH ##\n",
    "\n",
    "FinalModel = Final.predict(X_te)\n",
    "accuracy_score(y_te_b, FinalModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is .8771 with test set which is an improvement over SVC with default parameters (accuracy .8624)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (c) Train a Logistic Regression (search teh best hyper-parameters) and compare its performance with SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ehsanul\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ehsanul\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ehsanul\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ehsanul\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ehsanul\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ehsanul\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ehsanul\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8063630490956072 with C = 0.001\n",
      "0.8242894056847545 with C = 0.01\n",
      "0.8402777777777778 with C = 1\n",
      "0.8407622739018088 with C = 10\n",
      "0.8407622739018088 with C = 100\n",
      "0.8407622739018088 with C = 1000\n",
      "0.8407622739018088 with C = 100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8407622739018088"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "## YOUR CODE HERE ##\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "C_value = [.001,.01,1,10,100,1000,100000]\n",
    "results = []\n",
    "\n",
    "for i in C_value:\n",
    "  log_reg = LogisticRegression(C=i,random_state=42)\n",
    "  log_reg.fit(X_tr, y_tr_b)\n",
    "  log_reg_predict = log_reg.predict(X_te)\n",
    "  result = accuracy_score(y_te_b, log_reg_predict)\n",
    "  results.append(result)\n",
    "\n",
    "for j,i in zip(results,C_value):\n",
    "  print(j, \"with C =\",i)\n",
    "\n",
    "max(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Logictic regression, accuracy is .8407 on test set which is not as good as SVC. \n",
    "\n",
    "Logistic regression = accuracy .8407\n",
    "SVC with default hyper parameters = accuracy .8624\n",
    "SVC with tuned up hyper parameters = accuracy .8771\n",
    "\n",
    "Among all these models, SVC with tuned up parameters provides most accuracy on both training and test sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
